{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, RNN, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for Data Loading, normalization, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Reshape_to_input(X, T, Mat_dim):\n",
    "    \"\"\"\n",
    "    reshapes data\n",
    "    \"\"\"\n",
    "   \n",
    "    [Num_examples, dim] = X.shape\n",
    "    input_X = X[:,2:].reshape(Num_examples, Mat_dim, T)\n",
    "    \n",
    "    return input_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NormalizeTowardsMean(X):\n",
    "   # print(X.shape)\n",
    "    \"# Preprocessing: Subtract the mean feature - a question if it is feasible - all features are already in the same scale...\\n\",\n",
    "    # TODO: try -1 1 normalization\n",
    "    mean_feat = np.mean(X, axis=0, keepdims=True)\n",
    "   # print(mean_feat.shape)\n",
    "    X -= mean_feat\n",
    "    # Preprocessing: Divide by standard deviation. This ensures that each feature\\n\",\n",
    "    # has roughly the same scale.\\n\",\n",
    "    std_feat = np.std(X, axis=0, keepdims=True)\n",
    "    X /= std_feat\n",
    "    \n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Random_Selection_train_test (X_all, N):\n",
    "#    import random\n",
    "    \" This fucntion takes return train and test samples for the LSTM: X dataset, N - number of training samples (i.e persons)\"\n",
    "    Persons = X_all[:,1]\n",
    "    uniquePersons = np.unique(Persons)\n",
    "    random.shuffle(uniquePersons)\n",
    "    num_dim = np.shape(X_all)[1]\n",
    "    X_train = np.array([], dtype=np.int64).reshape(0,num_dim)\n",
    "    Y_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    Persons_train = np.array([])\n",
    "    Persons_test = np.array([])\n",
    "    #print(X_train.shape)\n",
    "    for Person in range(0,N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_train= np.append(X_train,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_train = np.append(Y_train, X_all[[indexes], 0])\n",
    "        Persons_train = np.append(Persons_train, label, axis = 0)\n",
    "    X_train=X_train.reshape(Y_train.size, num_dim)    \n",
    "    for Person in range(N,uniquePersons.size):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        X_test = np.append(X_test, X_all[[indexes], :][0,0,:,:])\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_test =  np.append(Y_test, X_all[[indexes], 0])\n",
    "        Persons_test = np.append(Persons_test, label, axis = 0)\n",
    "    X_test=X_test.reshape(Y_test.size, num_dim) \n",
    "    print('Persons for train: ')\n",
    "    print(np.unique(Persons_train))\n",
    "    returned_train = np.unique(Persons_train)\n",
    "    print('Persons for test: ')\n",
    "    print(np.unique(Persons_test))\n",
    "    return X_train, Y_train, X_test, Y_test, returned_train\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Random_Selection_train_val_test (X_all, N):\n",
    "#    import random\n",
    "    \" This fucntion takes return train and test samples for the LSTM: X dataset, N - number of training samples (i.e persons)\"\n",
    "    Persons = X_all[:,1]\n",
    "    uniquePersons = np.unique(Persons)\n",
    "    random.shuffle(uniquePersons)\n",
    "    num_dim = np.shape(X_all)[1]\n",
    "    X_train = np.array([], dtype=np.int64).reshape(0,num_dim)\n",
    "    Y_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    X_val = np.array([])\n",
    "    Y_val = np.array([])\n",
    "    Persons_train = np.array([])\n",
    "    Persons_val = np.array([])\n",
    "    Persons_test = np.array([])\n",
    "    \n",
    "    train_N =int(np.ceil(N*2/3))\n",
    "    \n",
    "    for Person in range(0,train_N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_train= np.append(X_train,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_train = np.append(Y_train, X_all[[indexes], 0])\n",
    "        Persons_train = np.append(Persons_train, label, axis = 0)\n",
    "    X_train=X_train.reshape(Y_train.size, num_dim)    \n",
    "    \n",
    "     \n",
    "    for Person in range(train_N,N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_val= np.append(X_val,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_val = np.append(Y_val, X_all[[indexes], 0])\n",
    "        Persons_val = np.append(Persons_val, label, axis = 0)\n",
    "    X_val=X_val.reshape(Y_val.size, num_dim)  \n",
    "    \n",
    "    for Person in range(N,uniquePersons.size):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        X_test = np.append(X_test, X_all[[indexes], :][0,0,:,:])\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_test =  np.append(Y_test, X_all[[indexes], 0])\n",
    "        Persons_test = np.append(Persons_test, label, axis = 0)\n",
    "    X_test=X_test.reshape(Y_test.size, num_dim) \n",
    "    print('Persons for train: ')\n",
    "    print(np.unique(Persons_train))\n",
    "    returned_train = np.unique(Persons_train)\n",
    "    print('Persons for val: ')\n",
    "    print(np.unique(Persons_val))\n",
    "    returned_val = np.unique(Persons_val)\n",
    "    print('Persons for test: ')\n",
    "    print(np.unique(Persons_test))\n",
    "    return X_train, Y_train, X_test, Y_test, X_val, Y_val, returned_train, returned_val\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(inputY, C):\n",
    "    N= inputY.size\n",
    "    Y=np.zeros((N,C))\n",
    "    for i in range (0, inputY.size):\n",
    "        Y[i, int(inputY[i]-1)] = 1\n",
    "        \n",
    "    \n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gait_model(data):\n",
    "    \"\"\"\n",
    "    Function creating the Gait model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input - data\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "   \n",
    "    ### START CODE HERE ###\n",
    "    gait_data = Input(data.shape, dtype='float32')\n",
    "    units = 128 \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "\n",
    "    X = Bidirectional(LSTM(units, return_sequences=True))( gait_data)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "   \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    X = Bidirectional(LSTM(units, return_sequences=False))(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(3)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=gait_data, outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load my dataset and parameters from a file\n",
    "from data_utils import loadfromfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myoptim=Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "    mcp_save = ModelCheckpoint(filepath, save_best_only =True, monitor = 'val_loss', mode ='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1, epsilon=1e-4, mode='min')\n",
    "    return [es, mcp_save, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters needed\n",
    "trials = 3\n",
    "epochs = 25\n",
    "batch_size = 30\n",
    "units = 192 # actually defind inside the funciton of the model - TODO - make it here\n",
    "path ='data/2_angles_only'\n",
    "Files, T, max_dim = loadfromfolder()\n",
    "#Where Files are names, T - my division into frames and max_dim - feature dimensionality\n",
    "fRes = open(\"Results.txt\",\"a+\") \n",
    "fRes.write(\"Number of units in LSTM = %d,  Epochs =  %d and batch size =  %d \\r\\n\" % (units, epochs,batch_size))\n",
    "for file in range(0, len(Files)):\n",
    "    name = Files[file]\n",
    "    t = T[file]\n",
    "    dim = max_dim[file]\n",
    "    name_w_path = path +\"/\"+name\n",
    "    fRes.write(\"Experiment %d from file %s \\r\\n\" % (file,name))\n",
    "    # here all the routine in One cell \n",
    "    X_all = pd.read_csv(name_w_path)\n",
    "    # the routine to run the same test N times, randomly shuffling the data\n",
    "    Accuracy  = np.zeros(shape=(trials))\n",
    "   \n",
    "    \n",
    "    for i in range(0,trials):\n",
    "        X_train, Y_train, X_test, Y_test, X_val, Y_val, returned_train, returned_val = Random_Selection_train_val_test (X_all.values, 14)\n",
    "        #namePersons = str(i)+'_'+'file'+ name[:-4] +'.txt'\n",
    "        #np.savetxt(namePersons, returned_train, delimiter=',', fmt='%d')   # X is an array\n",
    "        X_train = NormalizeTowardsMean(X_train)\n",
    "        X_test = NormalizeTowardsMean(X_test)\n",
    "        X_val = NormalizeTowardsMean(X_val)\n",
    "        \n",
    "        Y_train_oh = convert_to_one_hot(Y_train, C = 3)\n",
    "        Y_test_oh = convert_to_one_hot(Y_test, C = 3)\n",
    "        Y_val_oh = convert_to_one_hot(Y_val, C = 3)\n",
    "        \n",
    "        X_train = Reshape_to_input(X_train, t, dim)\n",
    "        X_test = Reshape_to_input(X_test, t, dim)\n",
    "        X_val = Reshape_to_input(X_val, t, dim)\n",
    "        \n",
    "        model = Gait_model((X_train[0,:,:]))\n",
    "        \n",
    "        file_path = 'Models/file_{}_model_wts.hdf5'.format(file)\n",
    "        callbacks = get_callbacks(filepath=file_path, patience = 35)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=myoptim, metrics=['accuracy'])\n",
    "              \n",
    "        \n",
    "        model.fit(X_train, Y_train_oh, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(X_val, Y_val_oh))\n",
    "        \n",
    "        loss, acc = model.evaluate(X_test, Y_test_oh)\n",
    "        \n",
    "        Accuracy[i]=acc\n",
    "        fRes.write(\"Final accuracy per trial %f \\r\\n\" % (acc))\n",
    "        \n",
    "    print(Accuracy)\n",
    "    fRes.write(\"Final mean accuracy is: %f \\r\\n\" % (np.mean(Accuracy)))\n",
    "fRes.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fRes.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
