{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, RNN, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for Data Loading, normalization, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reshape_to_input(X, T, Mat_dim):\n",
    "    \"\"\"\n",
    "    reshapes data\n",
    "    \"\"\"\n",
    "   \n",
    "    [Num_examples, dim] = X.shape\n",
    "    input_X = X[:,2:].reshape(Num_examples, Mat_dim, T)\n",
    "    \n",
    "    return input_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_towards_mean_train(X):\n",
    "   # print(X.shape)\n",
    "    \"# Preprocessing: Subtract the mean feature - a question if it is feasible - all features are already in the same scale...\"\n",
    "    \" returns the mean and standard deviation from the train set\"\n",
    "    # TODO: try -1 1 normalization\n",
    "    mean_feat = np.mean(X, axis=1, keepdims=True)\n",
    "   # print(mean_feat.shape)\n",
    "    X -= mean_feat\n",
    "    # Preprocessing: Divide by standard deviation. This ensures that each feature\\n\",\n",
    "    # has roughly the same scale.\\n\",\n",
    "    std_feat = np.std(X, axis=0, keepdims=True)\n",
    "    X /= std_feat\n",
    "    \n",
    "    return X, mean_feat, std_feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_towards_mean_testval(X, mean_feat, std_feat):\n",
    "   # print(X.shape)\n",
    "    \"# normalize test & val set...\\n\",\n",
    "    # TODO: try -1 1 normalization\n",
    "    X -= mean_feat\n",
    "    # Preprocessing: Divide by standard deviation. This ensures that each feature\\n\",\n",
    "    # has roughly the same scale.\\n\",\n",
    "    X /= std_feat\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Selection_train_test (X_all, N):\n",
    "#    import random\n",
    "    \" This fucntion takes return train and test samples for the LSTM: X dataset, N - number of training samples (i.e persons)\"\n",
    "    Persons = X_all[:,1]\n",
    "    uniquePersons = np.unique(Persons)\n",
    "    random.shuffle(uniquePersons)\n",
    "    num_dim = np.shape(X_all)[1]\n",
    "    X_train = np.array([], dtype=np.int64).reshape(0,num_dim)\n",
    "    Y_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    Persons_train = np.array([])\n",
    "    Persons_test = np.array([])\n",
    "    #print(X_train.shape)\n",
    "    for Person in range(0,N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_train= np.append(X_train,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_train = np.append(Y_train, X_all[[indexes], 0])\n",
    "        Persons_train = np.append(Persons_train, label, axis = 0)\n",
    "    X_train=X_train.reshape(Y_train.size, num_dim)    \n",
    "    for Person in range(N,uniquePersons.size):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        X_test = np.append(X_test, X_all[[indexes], :][0,0,:,:])\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_test =  np.append(Y_test, X_all[[indexes], 0])\n",
    "        Persons_test = np.append(Persons_test, label, axis = 0)\n",
    "    X_test=X_test.reshape(Y_test.size, num_dim) \n",
    "    print('Persons for train: ')\n",
    "    print(np.unique(Persons_train))\n",
    "    print('Persons for test: ')\n",
    "    print(np.unique(Persons_test))\n",
    "    return X_train, Y_train, X_test, Y_test, Persons_train\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Selection_train_val_test (X_all, N):\n",
    "#    import random\n",
    "    \" This fucntion takes return train, val and test samples for the LSTM: X dataset, N - number of training samples (i.e persons)\"\n",
    "    Persons = X_all[:,1]\n",
    "    uniquePersons = np.unique(Persons)\n",
    "    random.shuffle(uniquePersons)\n",
    "    num_dim = np.shape(X_all)[1]\n",
    "    X_train = np.array([], dtype=np.int64).reshape(0,num_dim)\n",
    "    Y_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    X_val = np.array([])\n",
    "    Y_val = np.array([])\n",
    "    Persons_train = np.array([])\n",
    "    Persons_val = np.array([])\n",
    "    Persons_test = np.array([])\n",
    "    \n",
    "    train_N =int(np.ceil(N*2/3))\n",
    "    \n",
    "    for Person in range(0,train_N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_train= np.append(X_train,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_train = np.append(Y_train, X_all[[indexes], 0])\n",
    "        Persons_train = np.append(Persons_train, label, axis = 0)\n",
    "    X_train=X_train.reshape(Y_train.size, num_dim)    \n",
    "    \n",
    "     \n",
    "    for Person in range(train_N,N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_val= np.append(X_val,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_val = np.append(Y_val, X_all[[indexes], 0])\n",
    "        Persons_val = np.append(Persons_val, label, axis = 0)\n",
    "    X_val=X_val.reshape(Y_val.size, num_dim)  \n",
    "    \n",
    "    for Person in range(N,uniquePersons.size):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        X_test = np.append(X_test, X_all[[indexes], :][0,0,:,:])\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_test =  np.append(Y_test, X_all[[indexes], 0])\n",
    "        Persons_test = np.append(Persons_test, label, axis = 0)\n",
    "    X_test=X_test.reshape(Y_test.size, num_dim) \n",
    "    print('Persons for train: ')\n",
    "    print(np.unique(Persons_train))\n",
    "    returned_train = np.unique(Persons_train)\n",
    "    print('Persons for val: ')\n",
    "    print(np.unique(Persons_val))\n",
    "    returned_val = np.unique(Persons_val)\n",
    "    print('Persons for test: ')\n",
    "    print(np.unique(Persons_test))\n",
    "    return X_train, Y_train, X_test, Y_test, X_val, Y_val, returned_train, returned_val\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(inputY, C):\n",
    "    \"Convert Y to one hot representation\"\n",
    "    N= inputY.size\n",
    "    Y=np.zeros((N,C))\n",
    "    for i in range (0, inputY.size):\n",
    "        Y[i, int(inputY[i]-1)] = 1\n",
    "        \n",
    "    \n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compund_model_assess(matrix, val_acc):\n",
    "    \" take the output of models and accuracy, and get the final score\"\n",
    "    num_classes = 3\n",
    "    ex, dim = matrice_models_for_test.shape\n",
    "    num_models = dim/3\n",
    "    \n",
    "    #binary assessment\n",
    "    # TO DO\n",
    "    \n",
    "    matrice_final =  np.zeros((ex,num_classes))\n",
    "    for i in range(0,dim,3):\n",
    "        matrice_final += matrix[:,i:i+3] * val_acc[int(i/3)]\n",
    "        # weight the model according the validation accuracy of the model\n",
    "    matrice_final /= num_models\n",
    "    return matrice_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gait_model(data):\n",
    "    \"\"\"\n",
    "    Function creating the Gait model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input - data\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "   \n",
    "    ### START CODE HERE ###\n",
    "    gait_data = Input(data.shape, dtype='float32')\n",
    "    units = 64 \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "\n",
    "    X = Bidirectional(LSTM(units, return_sequences=True))( gait_data)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "   \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    X = Bidirectional(LSTM(units, return_sequences=False),merge_mode='concat')(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(3)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=gait_data, outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my dataset and parameters from a file\n",
    "from data_utils import loadfromfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "myoptim=Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "    mcp_save = ModelCheckpoint(filepath, save_best_only =True, monitor = 'val_loss', mode ='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1, epsilon=1e-4, mode='min') #epsilon\n",
    "    return [es, mcp_save, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covmat_cycles_frames_29t_78f_angles_22persons.csv\n",
      "Persons for train: \n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 15. 16. 17. 18. 21. 22.]\n",
      "Persons for test: \n",
      "[ 1. 12. 13. 14. 19. 20.]\n",
      "Persons for train: \n",
      "[ 4.  5.  6.  7.  8.  9. 10. 16. 17. 18. 21.]\n",
      "Persons for test: \n",
      "[ 2.  3. 11. 15. 22.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khokhlov/virtenv/ml36/lib/python3.5/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 125 samples\n",
      "Epoch 1/40\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.1015 - acc: 0.3486 - val_loss: 1.0580 - val_acc: 0.3840\n",
      "Epoch 2/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 1.0460 - acc: 0.5141 - val_loss: 1.0151 - val_acc: 0.5680\n",
      "Epoch 3/40\n",
      "284/284 [==============================] - 8s 27ms/step - loss: 0.9944 - acc: 0.5634 - val_loss: 0.9739 - val_acc: 0.6240\n",
      "Epoch 4/40\n",
      "284/284 [==============================] - 8s 29ms/step - loss: 0.9418 - acc: 0.6303 - val_loss: 0.9298 - val_acc: 0.6400\n",
      "Epoch 5/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.8517 - acc: 0.7324 - val_loss: 0.8864 - val_acc: 0.6720\n",
      "Epoch 6/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.7978 - acc: 0.8028 - val_loss: 0.8366 - val_acc: 0.6800\n",
      "Epoch 7/40\n",
      "284/284 [==============================] - 8s 29ms/step - loss: 0.7665 - acc: 0.7289 - val_loss: 0.7831 - val_acc: 0.7040\n",
      "Epoch 8/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.6897 - acc: 0.7887 - val_loss: 0.7295 - val_acc: 0.7360\n",
      "Epoch 9/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.6109 - acc: 0.8239 - val_loss: 0.6809 - val_acc: 0.7520\n",
      "Epoch 10/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.5364 - acc: 0.8451 - val_loss: 0.6434 - val_acc: 0.7600\n",
      "Epoch 11/40\n",
      "284/284 [==============================] - 8s 27ms/step - loss: 0.4792 - acc: 0.8768 - val_loss: 0.6197 - val_acc: 0.7520\n",
      "Epoch 12/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.4243 - acc: 0.8697 - val_loss: 0.6053 - val_acc: 0.7680\n",
      "Epoch 13/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.3876 - acc: 0.9085 - val_loss: 0.5979 - val_acc: 0.7600\n",
      "Epoch 14/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.3466 - acc: 0.8803 - val_loss: 0.6117 - val_acc: 0.7520\n",
      "Epoch 15/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.3046 - acc: 0.9190 - val_loss: 0.6052 - val_acc: 0.7440\n",
      "Epoch 16/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.2832 - acc: 0.9120 - val_loss: 0.6080 - val_acc: 0.7280\n",
      "Epoch 17/40\n",
      "284/284 [==============================] - 7s 26ms/step - loss: 0.2332 - acc: 0.9401 - val_loss: 0.6034 - val_acc: 0.7280\n",
      "Epoch 18/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.2131 - acc: 0.9401 - val_loss: 0.6483 - val_acc: 0.7120\n",
      "Epoch 19/40\n",
      "284/284 [==============================] - 7s 26ms/step - loss: 0.1903 - acc: 0.9437 - val_loss: 0.6442 - val_acc: 0.7200\n",
      "Epoch 20/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.1400 - acc: 0.9859 - val_loss: 0.6795 - val_acc: 0.7040\n",
      "Epoch 21/40\n",
      "284/284 [==============================] - 8s 27ms/step - loss: 0.1393 - acc: 0.9683 - val_loss: 0.6837 - val_acc: 0.6960\n",
      "Epoch 22/40\n",
      "284/284 [==============================] - 8s 27ms/step - loss: 0.1142 - acc: 0.9754 - val_loss: 0.6983 - val_acc: 0.7040\n",
      "Epoch 23/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.0928 - acc: 0.9824 - val_loss: 0.7463 - val_acc: 0.6880\n",
      "Epoch 24/40\n",
      "284/284 [==============================] - 8s 29ms/step - loss: 0.0863 - acc: 0.9789 - val_loss: 0.7416 - val_acc: 0.6880\n",
      "Epoch 25/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.0703 - acc: 0.9894 - val_loss: 0.8383 - val_acc: 0.6800\n",
      "Epoch 26/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.0586 - acc: 0.9930 - val_loss: 0.8269 - val_acc: 0.6720\n",
      "Epoch 27/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.0541 - acc: 0.9894 - val_loss: 0.8522 - val_acc: 0.6640\n",
      "Epoch 28/40\n",
      "284/284 [==============================] - 8s 28ms/step - loss: 0.0426 - acc: 0.9965 - val_loss: 0.8730 - val_acc: 0.6640\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "138/138 [==============================] - 1s 6ms/step\n",
      "125/125 [==============================] - 1s 5ms/step\n",
      "0.7753623179767443 0.6639999942779541\n",
      "Persons for train: \n",
      "[ 2.  3.  4.  5.  7.  8.  9. 15. 16. 17. 21.]\n",
      "Persons for test: \n",
      "[ 6. 10. 11. 18. 22.]\n",
      "Train on 279 samples, validate on 130 samples\n",
      "Epoch 1/40\n",
      "279/279 [==============================] - 10s 37ms/step - loss: 1.1139 - acc: 0.3513 - val_loss: 1.0507 - val_acc: 0.4692\n",
      "Epoch 2/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 1.0964 - acc: 0.3871 - val_loss: 1.0358 - val_acc: 0.5077\n",
      "Epoch 3/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 1.0756 - acc: 0.4194 - val_loss: 1.0224 - val_acc: 0.5154\n",
      "Epoch 4/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 1.0502 - acc: 0.4659 - val_loss: 1.0122 - val_acc: 0.5308\n",
      "Epoch 5/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 1.0257 - acc: 0.5054 - val_loss: 1.0025 - val_acc: 0.5538\n",
      "Epoch 6/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 0.9953 - acc: 0.5735 - val_loss: 0.9940 - val_acc: 0.5769\n",
      "Epoch 7/40\n",
      "279/279 [==============================] - 9s 31ms/step - loss: 0.9925 - acc: 0.5771 - val_loss: 0.9852 - val_acc: 0.6077\n",
      "Epoch 8/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 0.9959 - acc: 0.5842 - val_loss: 0.9769 - val_acc: 0.6231\n",
      "Epoch 9/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.9946 - acc: 0.5556 - val_loss: 0.9695 - val_acc: 0.6385\n",
      "Epoch 10/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 0.9710 - acc: 0.6057 - val_loss: 0.9614 - val_acc: 0.6538\n",
      "Epoch 11/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 0.9555 - acc: 0.6129 - val_loss: 0.9539 - val_acc: 0.6615\n",
      "Epoch 12/40\n",
      "279/279 [==============================] - 9s 31ms/step - loss: 0.9742 - acc: 0.5914 - val_loss: 0.9467 - val_acc: 0.6692\n",
      "Epoch 13/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.9518 - acc: 0.6165 - val_loss: 0.9397 - val_acc: 0.6692\n",
      "Epoch 14/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.9146 - acc: 0.6308 - val_loss: 0.9332 - val_acc: 0.6692\n",
      "Epoch 15/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.9597 - acc: 0.5914 - val_loss: 0.9264 - val_acc: 0.6692\n",
      "Epoch 16/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.9156 - acc: 0.6595 - val_loss: 0.9198 - val_acc: 0.6615\n",
      "Epoch 17/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.9171 - acc: 0.6487 - val_loss: 0.9134 - val_acc: 0.6615\n",
      "Epoch 18/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.8986 - acc: 0.6810 - val_loss: 0.9062 - val_acc: 0.6692\n",
      "Epoch 19/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.9153 - acc: 0.6416 - val_loss: 0.8997 - val_acc: 0.6692\n",
      "Epoch 20/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8964 - acc: 0.6953 - val_loss: 0.8928 - val_acc: 0.6692\n",
      "Epoch 21/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8985 - acc: 0.6308 - val_loss: 0.8863 - val_acc: 0.6692\n",
      "Epoch 22/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.8921 - acc: 0.6774 - val_loss: 0.8795 - val_acc: 0.6692\n",
      "Epoch 23/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8746 - acc: 0.6631 - val_loss: 0.8729 - val_acc: 0.6692\n",
      "Epoch 24/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8533 - acc: 0.6953 - val_loss: 0.8657 - val_acc: 0.6692\n",
      "Epoch 25/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8607 - acc: 0.7133 - val_loss: 0.8593 - val_acc: 0.6769\n",
      "Epoch 26/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8457 - acc: 0.7204 - val_loss: 0.8524 - val_acc: 0.6769\n",
      "Epoch 27/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.8560 - acc: 0.6810 - val_loss: 0.8464 - val_acc: 0.6769\n",
      "Epoch 28/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8291 - acc: 0.7419 - val_loss: 0.8395 - val_acc: 0.6846\n",
      "Epoch 29/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8299 - acc: 0.6989 - val_loss: 0.8331 - val_acc: 0.6846\n",
      "Epoch 30/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8299 - acc: 0.6774 - val_loss: 0.8262 - val_acc: 0.6846\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7993 - acc: 0.7348 - val_loss: 0.8199 - val_acc: 0.6846\n",
      "Epoch 32/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8240 - acc: 0.6918 - val_loss: 0.8136 - val_acc: 0.6846\n",
      "Epoch 33/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7792 - acc: 0.7455 - val_loss: 0.8076 - val_acc: 0.6846\n",
      "Epoch 34/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.7901 - acc: 0.7168 - val_loss: 0.8021 - val_acc: 0.6923\n",
      "Epoch 35/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.7823 - acc: 0.7491 - val_loss: 0.7961 - val_acc: 0.7000\n",
      "Epoch 36/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.7613 - acc: 0.7276 - val_loss: 0.7898 - val_acc: 0.7000\n",
      "Epoch 37/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.7685 - acc: 0.7634 - val_loss: 0.7836 - val_acc: 0.7077\n",
      "Epoch 38/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7367 - acc: 0.7706 - val_loss: 0.7773 - val_acc: 0.7154\n",
      "Epoch 39/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7550 - acc: 0.7419 - val_loss: 0.7709 - val_acc: 0.7154\n",
      "Epoch 40/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7271 - acc: 0.7599 - val_loss: 0.7643 - val_acc: 0.7154\n",
      "138/138 [==============================] - 1s 5ms/step\n",
      "130/130 [==============================] - 1s 6ms/step\n",
      "0.7173913052116615 0.7153846153846154\n",
      "Persons for train: \n",
      "[ 3.  5.  6.  9. 11. 15. 16. 17. 18. 21. 22.]\n",
      "Persons for test: \n",
      "[ 2.  4.  7.  8. 10.]\n",
      "Train on 279 samples, validate on 130 samples\n",
      "Epoch 1/40\n",
      "279/279 [==============================] - 11s 39ms/step - loss: 1.1410 - acc: 0.2832 - val_loss: 1.1218 - val_acc: 0.2846\n",
      "Epoch 2/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 1.1060 - acc: 0.3297 - val_loss: 1.0978 - val_acc: 0.3154\n",
      "Epoch 3/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 1.0747 - acc: 0.4086 - val_loss: 1.0806 - val_acc: 0.3462\n",
      "Epoch 4/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 1.0525 - acc: 0.4444 - val_loss: 1.0664 - val_acc: 0.4077\n",
      "Epoch 5/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 1.0364 - acc: 0.5054 - val_loss: 1.0537 - val_acc: 0.4385\n",
      "Epoch 6/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 1.0109 - acc: 0.5197 - val_loss: 1.0426 - val_acc: 0.5308\n",
      "Epoch 7/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 1.0304 - acc: 0.4803 - val_loss: 1.0327 - val_acc: 0.5923\n",
      "Epoch 8/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 1.0167 - acc: 0.5233 - val_loss: 1.0234 - val_acc: 0.6154\n",
      "Epoch 9/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.9932 - acc: 0.5806 - val_loss: 1.0147 - val_acc: 0.6308\n",
      "Epoch 10/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.9877 - acc: 0.5842 - val_loss: 1.0067 - val_acc: 0.6462\n",
      "Epoch 11/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.9589 - acc: 0.6272 - val_loss: 0.9989 - val_acc: 0.6231\n",
      "Epoch 12/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.9701 - acc: 0.5914 - val_loss: 0.9912 - val_acc: 0.6231\n",
      "Epoch 13/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.9419 - acc: 0.6308 - val_loss: 0.9839 - val_acc: 0.6462\n",
      "Epoch 14/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.9383 - acc: 0.6595 - val_loss: 0.9767 - val_acc: 0.6462\n",
      "Epoch 15/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.9136 - acc: 0.6989 - val_loss: 0.9691 - val_acc: 0.6462\n",
      "Epoch 16/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.9102 - acc: 0.6703 - val_loss: 0.9619 - val_acc: 0.6462\n",
      "Epoch 17/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.9115 - acc: 0.6595 - val_loss: 0.9549 - val_acc: 0.6385\n",
      "Epoch 18/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8938 - acc: 0.7061 - val_loss: 0.9475 - val_acc: 0.6462\n",
      "Epoch 19/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.9009 - acc: 0.6774 - val_loss: 0.9401 - val_acc: 0.6385\n",
      "Epoch 20/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8748 - acc: 0.6738 - val_loss: 0.9332 - val_acc: 0.6385\n",
      "Epoch 21/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8733 - acc: 0.7204 - val_loss: 0.9265 - val_acc: 0.6385\n",
      "Epoch 22/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8706 - acc: 0.7168 - val_loss: 0.9194 - val_acc: 0.6462\n",
      "Epoch 23/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8456 - acc: 0.7168 - val_loss: 0.9128 - val_acc: 0.6462\n",
      "Epoch 24/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.8348 - acc: 0.7312 - val_loss: 0.9061 - val_acc: 0.6615\n",
      "Epoch 25/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.8255 - acc: 0.7276 - val_loss: 0.8994 - val_acc: 0.6615\n",
      "Epoch 26/40\n",
      "279/279 [==============================] - 7s 27ms/step - loss: 0.8369 - acc: 0.7025 - val_loss: 0.8925 - val_acc: 0.6615\n",
      "Epoch 27/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 0.8175 - acc: 0.7276 - val_loss: 0.8857 - val_acc: 0.6615\n",
      "Epoch 28/40\n",
      "279/279 [==============================] - 8s 30ms/step - loss: 0.7908 - acc: 0.7706 - val_loss: 0.8790 - val_acc: 0.6615\n",
      "Epoch 29/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.7925 - acc: 0.7527 - val_loss: 0.8723 - val_acc: 0.6615\n",
      "Epoch 30/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.7741 - acc: 0.7814 - val_loss: 0.8660 - val_acc: 0.6538\n",
      "Epoch 31/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.7749 - acc: 0.7742 - val_loss: 0.8595 - val_acc: 0.6615\n",
      "Epoch 32/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7729 - acc: 0.7527 - val_loss: 0.8532 - val_acc: 0.6538\n",
      "Epoch 33/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7649 - acc: 0.7634 - val_loss: 0.8467 - val_acc: 0.6538\n",
      "Epoch 34/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7517 - acc: 0.7706 - val_loss: 0.8400 - val_acc: 0.6538\n",
      "Epoch 35/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.7526 - acc: 0.7491 - val_loss: 0.8336 - val_acc: 0.6538\n",
      "Epoch 36/40\n",
      "279/279 [==============================] - 8s 28ms/step - loss: 0.7299 - acc: 0.7849 - val_loss: 0.8273 - val_acc: 0.6615\n",
      "Epoch 37/40\n",
      "279/279 [==============================] - 8s 27ms/step - loss: 0.7322 - acc: 0.7742 - val_loss: 0.8210 - val_acc: 0.6615\n",
      "Epoch 38/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.7143 - acc: 0.7885 - val_loss: 0.8152 - val_acc: 0.6769\n",
      "Epoch 39/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.6998 - acc: 0.7849 - val_loss: 0.8094 - val_acc: 0.6769\n",
      "Epoch 40/40\n",
      "279/279 [==============================] - 8s 29ms/step - loss: 0.6949 - acc: 0.8315 - val_loss: 0.8041 - val_acc: 0.6769\n",
      "138/138 [==============================] - 1s 6ms/step\n",
      "130/130 [==============================] - 1s 6ms/step\n",
      "0.6449275370957195 0.676923076923077\n",
      "Persons for train: \n",
      "[ 2.  4.  6.  7.  8. 10. 11. 15. 16. 17. 18.]\n",
      "Persons for test: \n",
      "[ 3.  5.  9. 21. 22.]\n",
      "Train on 268 samples, validate on 141 samples\n",
      "Epoch 1/40\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 1.0806 - acc: 0.4104 - val_loss: 1.0793 - val_acc: 0.3972\n",
      "Epoch 2/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 1.0574 - acc: 0.4478 - val_loss: 1.0576 - val_acc: 0.4823\n",
      "Epoch 3/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 1.0274 - acc: 0.4627 - val_loss: 1.0389 - val_acc: 0.5390\n",
      "Epoch 4/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.9869 - acc: 0.5522 - val_loss: 1.0233 - val_acc: 0.5816\n",
      "Epoch 5/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.9584 - acc: 0.5746 - val_loss: 1.0102 - val_acc: 0.5816\n",
      "Epoch 6/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.9527 - acc: 0.6119 - val_loss: 0.9978 - val_acc: 0.6099\n",
      "Epoch 7/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.9233 - acc: 0.6343 - val_loss: 0.9867 - val_acc: 0.6312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.9357 - acc: 0.5933 - val_loss: 0.9759 - val_acc: 0.6454\n",
      "Epoch 9/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.8908 - acc: 0.6903 - val_loss: 0.9653 - val_acc: 0.6738\n",
      "Epoch 10/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.8847 - acc: 0.6903 - val_loss: 0.9549 - val_acc: 0.6738\n",
      "Epoch 11/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.8915 - acc: 0.6418 - val_loss: 0.9450 - val_acc: 0.6879\n",
      "Epoch 12/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.8837 - acc: 0.6418 - val_loss: 0.9353 - val_acc: 0.6809\n",
      "Epoch 13/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.8569 - acc: 0.7052 - val_loss: 0.9261 - val_acc: 0.6809\n",
      "Epoch 14/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.8490 - acc: 0.6903 - val_loss: 0.9172 - val_acc: 0.6809\n",
      "Epoch 15/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.8354 - acc: 0.6567 - val_loss: 0.9082 - val_acc: 0.6809\n",
      "Epoch 16/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.8105 - acc: 0.7015 - val_loss: 0.8996 - val_acc: 0.6809\n",
      "Epoch 17/40\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.8136 - acc: 0.6567 - val_loss: 0.8913 - val_acc: 0.6809\n",
      "Epoch 18/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.7813 - acc: 0.7127 - val_loss: 0.8826 - val_acc: 0.6809\n",
      "Epoch 19/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.7880 - acc: 0.7090 - val_loss: 0.8741 - val_acc: 0.6738\n",
      "Epoch 20/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.7732 - acc: 0.7201 - val_loss: 0.8659 - val_acc: 0.6738\n",
      "Epoch 21/40\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.7424 - acc: 0.7649 - val_loss: 0.8580 - val_acc: 0.6738\n",
      "Epoch 22/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.7318 - acc: 0.7687 - val_loss: 0.8495 - val_acc: 0.6738\n",
      "Epoch 23/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.7153 - acc: 0.7948 - val_loss: 0.8418 - val_acc: 0.6738\n",
      "Epoch 24/40\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.7295 - acc: 0.7201 - val_loss: 0.8338 - val_acc: 0.6738\n",
      "Epoch 25/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6929 - acc: 0.7948 - val_loss: 0.8256 - val_acc: 0.6738\n",
      "Epoch 26/40\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.6896 - acc: 0.7836 - val_loss: 0.8176 - val_acc: 0.6738\n",
      "Epoch 27/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6815 - acc: 0.7724 - val_loss: 0.8098 - val_acc: 0.6738\n",
      "Epoch 28/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6789 - acc: 0.7799 - val_loss: 0.8022 - val_acc: 0.6738\n",
      "Epoch 29/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6678 - acc: 0.8097 - val_loss: 0.7951 - val_acc: 0.6738\n",
      "Epoch 30/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6882 - acc: 0.7575 - val_loss: 0.7884 - val_acc: 0.6738\n",
      "Epoch 31/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6680 - acc: 0.7463 - val_loss: 0.7814 - val_acc: 0.6667\n",
      "Epoch 32/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.6501 - acc: 0.7836 - val_loss: 0.7739 - val_acc: 0.6667\n",
      "Epoch 33/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6410 - acc: 0.7799 - val_loss: 0.7668 - val_acc: 0.6667\n",
      "Epoch 34/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6206 - acc: 0.8134 - val_loss: 0.7594 - val_acc: 0.6667\n",
      "Epoch 35/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.6078 - acc: 0.8022 - val_loss: 0.7520 - val_acc: 0.6667\n",
      "Epoch 36/40\n",
      "268/268 [==============================] - 7s 28ms/step - loss: 0.6026 - acc: 0.8060 - val_loss: 0.7460 - val_acc: 0.6738\n",
      "Epoch 37/40\n",
      "268/268 [==============================] - 8s 28ms/step - loss: 0.6087 - acc: 0.8284 - val_loss: 0.7393 - val_acc: 0.6738\n",
      "Epoch 38/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.5979 - acc: 0.8134 - val_loss: 0.7330 - val_acc: 0.6738\n",
      "Epoch 39/40\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.5818 - acc: 0.8246 - val_loss: 0.7265 - val_acc: 0.6738\n",
      "Epoch 40/40\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 0.5819 - acc: 0.7985 - val_loss: 0.7206 - val_acc: 0.6667\n",
      "138/138 [==============================] - 1s 6ms/step\n",
      "141/141 [==============================] - 1s 5ms/step\n",
      "0.7028985507246377 0.6666666687803066\n",
      "Persons for train: \n",
      "[ 2.  3.  4.  5.  8.  9. 11. 16. 17. 18. 21.]\n",
      "Persons for test: \n",
      "[ 6.  7. 10. 15. 22.]\n",
      "Train on 282 samples, validate on 127 samples\n",
      "Epoch 1/40\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.0915 - acc: 0.3582 - val_loss: 1.0797 - val_acc: 0.4016\n",
      "Epoch 2/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 1.0853 - acc: 0.4220 - val_loss: 1.0509 - val_acc: 0.5039\n",
      "Epoch 3/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 1.0334 - acc: 0.4752 - val_loss: 1.0270 - val_acc: 0.5669\n",
      "Epoch 4/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 1.0151 - acc: 0.4752 - val_loss: 1.0089 - val_acc: 0.6220\n",
      "Epoch 5/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 1.0038 - acc: 0.5142 - val_loss: 0.9911 - val_acc: 0.6378\n",
      "Epoch 6/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.9790 - acc: 0.5390 - val_loss: 0.9755 - val_acc: 0.6457\n",
      "Epoch 7/40\n",
      "282/282 [==============================] - 7s 26ms/step - loss: 0.9494 - acc: 0.6418 - val_loss: 0.9602 - val_acc: 0.6693\n",
      "Epoch 8/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.9302 - acc: 0.6773 - val_loss: 0.9462 - val_acc: 0.6772\n",
      "Epoch 9/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.9152 - acc: 0.6135 - val_loss: 0.9326 - val_acc: 0.6850\n",
      "Epoch 10/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 0.9078 - acc: 0.6773 - val_loss: 0.9202 - val_acc: 0.6929\n",
      "Epoch 11/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.9012 - acc: 0.6489 - val_loss: 0.9076 - val_acc: 0.7087\n",
      "Epoch 12/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.8811 - acc: 0.6809 - val_loss: 0.8956 - val_acc: 0.7087\n",
      "Epoch 13/40\n",
      "282/282 [==============================] - 7s 27ms/step - loss: 0.8546 - acc: 0.6809 - val_loss: 0.8846 - val_acc: 0.7087\n",
      "Epoch 14/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 0.8489 - acc: 0.7057 - val_loss: 0.8734 - val_acc: 0.7087\n",
      "Epoch 15/40\n",
      "282/282 [==============================] - 7s 26ms/step - loss: 0.8368 - acc: 0.7057 - val_loss: 0.8621 - val_acc: 0.7008\n",
      "Epoch 16/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.8103 - acc: 0.7305 - val_loss: 0.8506 - val_acc: 0.7008\n",
      "Epoch 17/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 0.8002 - acc: 0.7411 - val_loss: 0.8404 - val_acc: 0.7008\n",
      "Epoch 18/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 0.7964 - acc: 0.7092 - val_loss: 0.8309 - val_acc: 0.7008\n",
      "Epoch 19/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.7705 - acc: 0.7482 - val_loss: 0.8206 - val_acc: 0.6929\n",
      "Epoch 20/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.7791 - acc: 0.7057 - val_loss: 0.8112 - val_acc: 0.6929\n",
      "Epoch 21/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.7661 - acc: 0.7199 - val_loss: 0.8021 - val_acc: 0.6929\n",
      "Epoch 22/40\n",
      "282/282 [==============================] - 7s 26ms/step - loss: 0.7504 - acc: 0.7589 - val_loss: 0.7920 - val_acc: 0.6929\n",
      "Epoch 23/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 0.7292 - acc: 0.7518 - val_loss: 0.7835 - val_acc: 0.7008\n",
      "Epoch 24/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.7384 - acc: 0.7199 - val_loss: 0.7746 - val_acc: 0.7008\n",
      "Epoch 25/40\n",
      "282/282 [==============================] - 8s 29ms/step - loss: 0.7154 - acc: 0.7482 - val_loss: 0.7667 - val_acc: 0.7008\n",
      "Epoch 26/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.7117 - acc: 0.7695 - val_loss: 0.7591 - val_acc: 0.7008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6894 - acc: 0.7411 - val_loss: 0.7502 - val_acc: 0.7087\n",
      "Epoch 28/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6819 - acc: 0.7660 - val_loss: 0.7431 - val_acc: 0.7087\n",
      "Epoch 29/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6724 - acc: 0.7695 - val_loss: 0.7356 - val_acc: 0.7008\n",
      "Epoch 30/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6536 - acc: 0.7979 - val_loss: 0.7291 - val_acc: 0.7008\n",
      "Epoch 31/40\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 0.6607 - acc: 0.7801 - val_loss: 0.7222 - val_acc: 0.7008\n",
      "Epoch 32/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6468 - acc: 0.8121 - val_loss: 0.7166 - val_acc: 0.7008\n",
      "Epoch 33/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6491 - acc: 0.7801 - val_loss: 0.7107 - val_acc: 0.7008\n",
      "Epoch 34/40\n",
      "282/282 [==============================] - 8s 30ms/step - loss: 0.6201 - acc: 0.7801 - val_loss: 0.7054 - val_acc: 0.7008\n",
      "Epoch 35/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6095 - acc: 0.8050 - val_loss: 0.7004 - val_acc: 0.7008\n",
      "Epoch 36/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.5998 - acc: 0.7908 - val_loss: 0.6955 - val_acc: 0.6929\n",
      "Epoch 37/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.5826 - acc: 0.8298 - val_loss: 0.6912 - val_acc: 0.6929\n",
      "Epoch 38/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.6043 - acc: 0.8298 - val_loss: 0.6874 - val_acc: 0.6929\n",
      "Epoch 39/40\n",
      "282/282 [==============================] - 8s 27ms/step - loss: 0.5940 - acc: 0.8085 - val_loss: 0.6830 - val_acc: 0.6929\n",
      "Epoch 40/40\n",
      "282/282 [==============================] - 8s 30ms/step - loss: 0.5748 - acc: 0.8014 - val_loss: 0.6791 - val_acc: 0.7008\n",
      "138/138 [==============================] - 1s 6ms/step\n",
      "127/127 [==============================] - 1s 5ms/step\n",
      "0.6884057988291201 0.7007873959428682\n",
      "[0.77536232 0.71739131 0.64492754 0.70289855 0.6884058 ]\n",
      "Final Model accuracy from 5 compound models is 0.775362 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters needed\n",
    "trials = 1\n",
    "models = 5\n",
    "epochs = 40\n",
    "batch_size = 21\n",
    "\n",
    "units = 64 # actually defind inside the funciton of the model - TODO - make it here\n",
    "path ='data/best'\n",
    "Files, T, max_dim = loadfromfolder()\n",
    "#Where Files are names, T - my division into frames and max_dim - feature dimensionality\n",
    "fRes = open(\"Results_BiDirCompound_covmat.txt\",\"a+\") \n",
    "fRes.write(\"Number of units in LSTM = %d,  Epochs =  %d and batch size =  %d \\r\\n\" % (units, epochs,batch_size))\n",
    "\n",
    "for file in range(0,len(Files)): \n",
    "    name = Files[file]\n",
    "    t = T[file]\n",
    "    dim = max_dim[file]\n",
    "    name_w_path = path +\"/\"+name\n",
    "    fRes.write(\"Experiment %d from file %s \\r\\n\" % (file,name))\n",
    "    # here all the routine in One cell \n",
    "    X_all = pd.read_csv(name_w_path)\n",
    "    # the routine to run the same test N times, randomly shuffling the data\n",
    "    for j in range(0,trials):\n",
    "        fRes.write(\"Data partinioning random  %d out of %d\\r\\n\\n\" % (j, trials))\n",
    "        X_train_all, Y_train_all, X_test, Y_test, returned_train = Random_Selection_train_test (X_all.values, 16)\n",
    "        Y_test_oh = convert_to_one_hot(Y_test, C = 3)\n",
    "        X_test = Reshape_to_input(X_test, t, dim)\n",
    "    \n",
    "        matrice_models_for_test = np.array([], dtype=np.float).reshape(Y_test.size,0) \n",
    "        # here is the final matrix, which will save the probability assigned for each class\n",
    "        Accuracy  = np.zeros(shape=(models))\n",
    "        val_accuracy  = np.zeros(shape=(models))\n",
    "        for i in range(0,models):\n",
    "            \n",
    "            modelname ='f'+ str(file) +'t'+ str(j) + 'f' + str(i) #define model index\n",
    "        \n",
    "            X_train, Y_train, X_val, Y_val, returned_train = Random_Selection_train_test (X_train_all, 11)\n",
    "\n",
    "            Y_train_oh = convert_to_one_hot(Y_train, C = 3)\n",
    "            Y_val_oh = convert_to_one_hot(Y_val, C = 3)\n",
    "        \n",
    "            X_train = Reshape_to_input(X_train, t, dim)\n",
    "            X_val = Reshape_to_input(X_val, t, dim)\n",
    "        \n",
    "        \n",
    "            model = Gait_model((X_train[0,:,:]))\n",
    "        \n",
    "            file_path = 'models/dif_vote/file_{}_model_wts.hdf5'.format(modelname)\n",
    "            callbacks = get_callbacks(filepath=file_path, patience = 35)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=myoptim, metrics=['accuracy'])\n",
    "              \n",
    "              \n",
    "        \n",
    "            model.fit(X_train, Y_train_oh, epochs=epochs,\\\n",
    "                      batch_size=batch_size, shuffle=True, \\\n",
    "                      validation_data=(X_val, Y_val_oh), callbacks=callbacks)\n",
    "        \n",
    "            loss, acc = model.evaluate(X_test, Y_test_oh)\n",
    "            loss, val_accuracy[i] = model.evaluate(X_val, Y_val_oh)\n",
    "            probability_assigned = model.predict(X_test) #verbose=1\n",
    "            matrice_models_for_test = np.hstack([matrice_models_for_test, probability_assigned]) # just stack each matrix horizontally\n",
    "            Accuracy[i]=acc\n",
    "            print(acc, val_accuracy[i])\n",
    "            fRes.write(\"Final accuracy per trial %f \\r\\n\" % (acc))\n",
    "        print(Accuracy)\n",
    "        fRes.write(\"Final mean accuracy is: %f \\r\\n\" % (np.mean(Accuracy)))\n",
    "        # calculate final compunt accuracy\n",
    "        final=compund_model_assess(matrice_models_for_test, val_accuracy)\n",
    "        Y_test_compound = np.argmax(final, axis=1)+1\n",
    "        print(\"Final Model accuracy from %d compound models is %f \\r\\n\\n\" % (models, accuracy_score(Y_test,Y_test_compound)))\n",
    "fRes.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different things to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(matrice_models_for_test, interpolation='nearest', cmap=plt.cm.ocean )\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "plt.pcolor(matrice_models_for_test)\n",
    "plt.colorbar()\n",
    "plt.axvline(x=[3], color='r', linestyle='-')\n",
    "plt.axvline(x=[6], color='r', linestyle='-')\n",
    "plt.axvline(x=[9], color='r', linestyle='-')\n",
    "plt.axvline(x=[12], color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_compound = np.argmax(final, axis=1)+1\n",
    "print(\"Final Model accuracy from %d compound models is %f\" % (trials, accuracy_score(Y_test,Y_test_compound)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.95454545 0.04545455 0.        ]\n",
      " [0.06976744 0.51162791 0.41860465]\n",
      " [0.01960784 0.1372549  0.84313725]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(Y_test,Y_test_compound)\n",
    "class_names = ['knee', 'normal', 'padding']\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 8, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_49 (Bidirectio (None, 8, 128)            40960     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_50 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 140,163\n",
      "Trainable params: 140,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
