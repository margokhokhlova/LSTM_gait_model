{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 -Gait Modeal:  LSTMs in Keras: \n",
    "\n",
    " LSTM model that takes as inputs my gait angles features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, RNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "import tensorflow as tf\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547, 398)\n",
      "   1  1.1  1.6799  1.2544  1.0591   3.102   2.619  1.9555  0.43623  0.36831  \\\n",
      "0  1    1  1.4158  3.4054  1.5435  3.3255  1.5072  3.6255  0.63371  0.28722   \n",
      "\n",
      "     ...      0.029403  0.059589  -0.31565  0.010169  0.070043  -0.36121  \\\n",
      "0    ...      0.027058  0.016473  -0.66958 -0.047546  0.005244  -0.72137   \n",
      "\n",
      "   -0.020401  -0.084859  0.52289  -0.062316  \n",
      "0  -0.073476   -0.12972   1.1659   0.051024  \n",
      "\n",
      "[1 rows x 398 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data with Pandas\n",
    "import pandas as pd\n",
    "X_all = pd.read_csv(\"cycles_for_LSTM/covmat_cycles_frames_11t_36f_anglesZX_22persons.csv\")\n",
    "# print things about the files\n",
    "print(X_all.shape)\n",
    "print(X_all.head(1))\n",
    "# Define the T - total frames (in time dimension) and Mat_dim - the dimensionality of a single matrix\n",
    "T = 11\n",
    "Mat_dim = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Reshape_to_input(X, T, Mat_dim):\n",
    "    \"\"\"\n",
    "    reshapes data\n",
    "    \"\"\"\n",
    "   \n",
    "    [Num_examples, dim] = X.shape\n",
    "    input_X = X[:,2:].reshape(Num_examples, Mat_dim, T)\n",
    "    \n",
    "    return input_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NormalizeTowardsMean(X):\n",
    "   # print(X.shape)\n",
    "    \"# Preprocessing: Subtract the mean feature\\n\",\n",
    "    mean_feat = np.mean(X, axis=0, keepdims=True)\n",
    "   # print(mean_feat.shape)\n",
    "    X -= mean_feat\n",
    "    # Preprocessing: Divide by standard deviation. This ensures that each feature\\n\",\n",
    "    # has roughly the same scale.\\n\",\n",
    "    std_feat = np.std(X, axis=0, keepdims=True)\n",
    "    X /= std_feat\n",
    "    \n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Random_Selection_train_test (X_all, N):\n",
    "#    import random\n",
    "    \" This fucntion takes return train and test samples for the LSTM: X dataset, N - number of training samples (i.e persons)\"\n",
    "    Persons = X_all[:,1]\n",
    "    uniquePersons = np.unique(Persons)\n",
    "    random.shuffle(uniquePersons)\n",
    "    num_dim = np.shape(X_all)[1]\n",
    "    X_train = np.array([], dtype=np.int64).reshape(0,num_dim)\n",
    "    Y_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    Persons_train = np.array([])\n",
    "    Persons_test = np.array([])\n",
    "    #print(X_train.shape)\n",
    "    for Person in range(0,N):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        #print(X_all[[indexes], :][0,0,:,:].shape)\n",
    "        Person_X_val = X_all[[indexes], :][0,0,:,:]\n",
    "        X_train= np.append(X_train,Person_X_val)\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_train = np.append(Y_train, X_all[[indexes], 0])\n",
    "        Persons_train = np.append(Persons_train, label, axis = 0)\n",
    "    X_train=X_train.reshape(Y_train.size, num_dim)    \n",
    "    for Person in range(N,uniquePersons.size):\n",
    "        indexes = np.where(X_all[:,1]==uniquePersons[Person])\n",
    "        X_test = np.append(X_test, X_all[[indexes], :][0,0,:,:])\n",
    "        label =  np.full((indexes[0].size),uniquePersons[Person])\n",
    "        Y_test =  np.append(Y_test, X_all[[indexes], 0])\n",
    "        Persons_test = np.append(Persons_test, label, axis = 0)\n",
    "    X_test=X_test.reshape(Y_test.size, num_dim) \n",
    "    print('Persons for train: ')\n",
    "    print(np.unique(Persons_train))\n",
    "    print('Persons for test: ')\n",
    "    print(np.unique(Persons_test))\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(inputY, C):\n",
    "    N= inputY.size\n",
    "    Y=np.zeros((N,C))\n",
    "    for i in range (0, inputY.size):\n",
    "        Y[i, int(inputY[i]-1)] = 1\n",
    "        \n",
    "    \n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons for train: \n",
      "[  3.   4.   5.   6.   7.   8.   9.  10.  11.  15.  16.  19.  21.  22.]\n",
      "Persons for test: \n",
      "[  1.   2.  12.  13.  14.  17.  18.  20.]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = Random_Selection_train_test (X_all.values, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 398)\n",
      "(1, 398)\n",
      "(211, 398)\n",
      "(1, 398)\n"
     ]
    }
   ],
   "source": [
    "X_train = NormalizeTowardsMean(X_train)\n",
    "X_test = NormalizeTowardsMean(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras and mini-batching \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gait_model(data):\n",
    "    \"\"\"\n",
    "    Function creating the Gait model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input - data\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "   \n",
    "    ### START CODE HERE ###\n",
    "    gait_data = Input(data.shape, dtype='float32')\n",
    " \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "\n",
    "    X = LSTM(128, return_sequences=True)( gait_data)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "   \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(3)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=gait_data, outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X_train = Reshape_to_input(X_train, T, Mat_dim)\n",
    "X_test = Reshape_to_input(X_test,T, Mat_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create your model and check its summary. Because all sentences in the dataset are less than 10 words, we chose `max_len = 10`.  You should see your architecture, it uses \"20,223,927\" parameters, of which 20,000,050 (the word embeddings) are non-trainable, and the remaining 223,877 are. Because our vocabulary size has 400,001 words (with valid indices from 0 to 400,000) there are 400,001\\*50 = 20,000,050 non-trainable parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 36, 11)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 36, 11)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 36, 128)           71680     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 203,651\n",
      "Trainable params: 203,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "model = Gait_model((X_train[0,:,:]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, after creating your model in Keras, you need to compile it and define what loss, optimizer and metrics your are want to use. Compile your model using `categorical_crossentropy` loss, `adam` optimizer and `['accuracy']` metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to train your model. Your Emojifier-V2 `model` takes as input an array of shape (`m`, `max_len`) and outputs probability vectors of shape (`m`, `number of classes`). We thus have to convert X_train (array of sentences as strings) to X_train_indices (array of sentences as list of word indices), and Y_train (labels as indices) to Y_train_oh (labels as one-hot vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 3)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Keras model on `X_train_indices` and `Y_train_oh`. We will use `epochs = 50` and `batch_size = 32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "354/354 [==============================] - 12s 34ms/step - loss: 1.0095 - acc: 0.5282\n",
      "Epoch 2/25\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 0.7653 - acc: 0.6356\n",
      "Epoch 3/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6741 - acc: 0.7062\n",
      "Epoch 4/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.5817 - acc: 0.7345\n",
      "Epoch 5/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.4830 - acc: 0.7853\n",
      "Epoch 6/25\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.4016 - acc: 0.8333\n",
      "Epoch 7/25\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.3229 - acc: 0.8983\n",
      "Epoch 8/25\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.2605 - acc: 0.8898\n",
      "Epoch 9/25\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.2056 - acc: 0.9209\n",
      "Epoch 10/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1649 - acc: 0.9407\n",
      "Epoch 11/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1343 - acc: 0.9633\n",
      "Epoch 12/25\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0647 - acc: 0.9802\n",
      "Epoch 13/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0653 - acc: 0.9802\n",
      "Epoch 14/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 15/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0433 - acc: 0.9859\n",
      "Epoch 16/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0248 - acc: 0.9915\n",
      "Epoch 17/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0107 - acc: 0.9972\n",
      "Epoch 18/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0145 - acc: 0.9972\n",
      "Epoch 19/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0326 - acc: 0.9859\n",
      "Epoch 20/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 0.9774\n",
      "Epoch 21/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0486 - acc: 0.9859\n",
      "Epoch 22/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0522 - acc: 0.9831\n",
      "Epoch 23/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0558 - acc: 0.9831\n",
      "Epoch 24/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0503 - acc: 0.9859\n",
      "Epoch 25/25\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0258 - acc: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xed9a4647b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_oh, epochs = 25 , batch_size = 25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model should perform close to **100% accuracy** on the training set. The exact accuracy you get may be a little different. Run the following cell to evaluate your model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 6ms/step\n",
      "\n",
      "Test accuracy =  0.673575129534\n"
     ]
    }
   ],
   "source": [
    "#X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "#Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons for train: \n",
      "[  2.   3.   4.   5.   6.   7.  10.  11.  12.  14.  15.  18.  19.  22.]\n",
      "Persons for test: \n",
      "[  1.   8.   9.  13.  16.  17.  20.  21.]\n",
      "Epoch 1/20\n",
      "353/353 [==============================] - 12s 35ms/step - loss: 1.0721 - acc: 0.4986\n",
      "Epoch 2/20\n",
      "353/353 [==============================] - 2s 4ms/step - loss: 0.9825 - acc: 0.5467\n",
      "Epoch 3/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.8969 - acc: 0.6204\n",
      "Epoch 4/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.8191 - acc: 0.6601\n",
      "Epoch 5/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.7916 - acc: 0.6487\n",
      "Epoch 6/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.7448 - acc: 0.6997\n",
      "Epoch 7/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.7025 - acc: 0.7195\n",
      "Epoch 8/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.6820 - acc: 0.6941\n",
      "Epoch 9/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.6009 - acc: 0.7535\n",
      "Epoch 10/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.5614 - acc: 0.7592\n",
      "Epoch 11/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.5192 - acc: 0.7762\n",
      "Epoch 12/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.5128 - acc: 0.7960\n",
      "Epoch 13/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.4930 - acc: 0.7875\n",
      "Epoch 14/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.4835 - acc: 0.8215\n",
      "Epoch 15/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.4775 - acc: 0.8159\n",
      "Epoch 16/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.4351 - acc: 0.8385\n",
      "Epoch 17/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.3938 - acc: 0.8414\n",
      "Epoch 18/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.3704 - acc: 0.8527\n",
      "Epoch 19/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.3638 - acc: 0.8470\n",
      "Epoch 20/20\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.3259 - acc: 0.8867\n",
      "194/194 [==============================] - 0s 2ms/step\n",
      "Persons for train: \n",
      "[  3.   6.   7.   8.   9.  10.  13.  15.  16.  17.  18.  20.  21.  22.]\n",
      "Persons for test: \n",
      "[  1.   2.   4.   5.  11.  12.  14.  19.]\n",
      "Epoch 1/20\n",
      "340/340 [==============================] - 13s 40ms/step - loss: 1.0672 - acc: 0.4824\n",
      "Epoch 2/20\n",
      "340/340 [==============================] - 2s 5ms/step - loss: 0.9349 - acc: 0.5676\n",
      "Epoch 3/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.8306 - acc: 0.6324\n",
      "Epoch 4/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.8022 - acc: 0.6529\n",
      "Epoch 5/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.7702 - acc: 0.6882\n",
      "Epoch 6/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.7021 - acc: 0.7000\n",
      "Epoch 7/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.6298 - acc: 0.7618\n",
      "Epoch 8/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.6241 - acc: 0.7324\n",
      "Epoch 9/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.5214 - acc: 0.7853\n",
      "Epoch 10/20\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.5282 - acc: 0.7882\n",
      "Epoch 11/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.4803 - acc: 0.8059\n",
      "Epoch 12/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.4242 - acc: 0.8176\n",
      "Epoch 13/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.3835 - acc: 0.8588\n",
      "Epoch 14/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.3228 - acc: 0.8824\n",
      "Epoch 15/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.3506 - acc: 0.8647\n",
      "Epoch 16/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.3025 - acc: 0.8824\n",
      "Epoch 17/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.2550 - acc: 0.9000\n",
      "Epoch 18/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.2230 - acc: 0.9029\n",
      "Epoch 19/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.1963 - acc: 0.9206\n",
      "Epoch 20/20\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 0.1907 - acc: 0.9353\n",
      "207/207 [==============================] - 0s 2ms/step\n",
      "Persons for train: \n",
      "[  5.   7.   8.   9.  10.  11.  12.  13.  15.  16.  18.  19.  20.  22.]\n",
      "Persons for test: \n",
      "[  1.   2.   3.   4.   6.  14.  17.  21.]\n",
      "Epoch 1/20\n",
      "342/342 [==============================] - 13s 38ms/step - loss: 1.0605 - acc: 0.4561\n",
      "Epoch 2/20\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.9249 - acc: 0.5906\n",
      "Epoch 3/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.8098 - acc: 0.6170\n",
      "Epoch 4/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.7465 - acc: 0.6491\n",
      "Epoch 5/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.6869 - acc: 0.6813\n",
      "Epoch 6/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.6528 - acc: 0.7193\n",
      "Epoch 7/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5984 - acc: 0.7456\n",
      "Epoch 8/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5238 - acc: 0.7895\n",
      "Epoch 9/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.4968 - acc: 0.7807\n",
      "Epoch 10/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.4637 - acc: 0.8041\n",
      "Epoch 11/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.4701 - acc: 0.7895\n",
      "Epoch 12/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.4263 - acc: 0.8129\n",
      "Epoch 13/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.3383 - acc: 0.8889\n",
      "Epoch 14/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.3429 - acc: 0.8743\n",
      "Epoch 15/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.3009 - acc: 0.8860\n",
      "Epoch 16/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.2399 - acc: 0.9211\n",
      "Epoch 17/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.2605 - acc: 0.8977\n",
      "Epoch 18/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.2218 - acc: 0.9240\n",
      "Epoch 19/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.1664 - acc: 0.9415\n",
      "Epoch 20/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.1728 - acc: 0.9298\n",
      "205/205 [==============================] - 1s 4ms/step\n",
      "Persons for train: \n",
      "[  3.   4.   5.   6.   7.   8.   9.  11.  12.  16.  18.  20.  21.  22.]\n",
      "Persons for test: \n",
      "[  1.   2.  10.  13.  14.  15.  17.  19.]\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 1.0512 - acc: 0.5028\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.9261 - acc: 0.5833\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.8360 - acc: 0.6222\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.7814 - acc: 0.6528\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.7408 - acc: 0.6528\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.6859 - acc: 0.6917\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.7060 - acc: 0.6833\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.6490 - acc: 0.6972\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.5814 - acc: 0.7417\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.5585 - acc: 0.7583\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.5373 - acc: 0.7556\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.5197 - acc: 0.7528\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.4561 - acc: 0.8167\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.4187 - acc: 0.8194\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.4566 - acc: 0.8028\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.3994 - acc: 0.8389\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.3791 - acc: 0.8389\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 1s 3ms/step - loss: 0.3194 - acc: 0.8694\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.2776 - acc: 0.8972\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.2460 - acc: 0.8972\n",
      "187/187 [==============================] - 1s 3ms/step\n",
      "Persons for train: \n",
      "[  1.   3.   6.   8.   9.  11.  13.  16.  17.  18.  19.  20.  21.  22.]\n",
      "Persons for test: \n",
      "[  2.   4.   5.   7.  10.  12.  14.  15.]\n",
      "Epoch 1/20\n",
      "342/342 [==============================] - 12s 37ms/step - loss: 1.0556 - acc: 0.4737\n",
      "Epoch 2/20\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.8769 - acc: 0.5614\n",
      "Epoch 3/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.7880 - acc: 0.6345\n",
      "Epoch 4/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.7551 - acc: 0.6784\n",
      "Epoch 5/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.7080 - acc: 0.6784\n",
      "Epoch 6/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.6632 - acc: 0.7193\n",
      "Epoch 7/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.6036 - acc: 0.7515\n",
      "Epoch 8/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5875 - acc: 0.7339\n",
      "Epoch 9/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5513 - acc: 0.7544\n",
      "Epoch 10/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.5075 - acc: 0.7836\n",
      "Epoch 11/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.4941 - acc: 0.8041\n",
      "Epoch 12/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.4406 - acc: 0.8129\n",
      "Epoch 13/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.4279 - acc: 0.8392\n",
      "Epoch 14/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.3976 - acc: 0.8246\n",
      "Epoch 15/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.3892 - acc: 0.8509\n",
      "Epoch 16/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.3354 - acc: 0.8626\n",
      "Epoch 17/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.2960 - acc: 0.8801\n",
      "Epoch 18/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.3127 - acc: 0.8801\n",
      "Epoch 19/20\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.2745 - acc: 0.9064\n",
      "Epoch 20/20\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.2851 - acc: 0.8918\n",
      "205/205 [==============================] - 1s 3ms/step\n",
      "[ 0.66494845  0.55555556  0.55609756  0.59893049  0.58048781]\n"
     ]
    }
   ],
   "source": [
    "trials = 5\n",
    "Accuracy = X_train = np.zeros(shape=(trials))\n",
    "\n",
    "for i in range(0,trials):\n",
    "    X_train, Y_train, X_test, Y_test = Random_Selection_train_test (X_all.values, 14)\n",
    "    X_train = NormalizeTowardsMean(X_train)\n",
    "    X_test = NormalizeTowardsMean(X_test)\n",
    "\n",
    "    Y_train_oh = convert_to_one_hot(Y_train, C = 3)\n",
    "    Y_test_oh = convert_to_one_hot(Y_test, C = 3)\n",
    "    X_train = Reshape_to_input(X_train, T, Mat_dim)\n",
    "    X_test = Reshape_to_input(X_test, T, Mat_dim)\n",
    "    model = Gait_model((X_train[0,:,:]))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train_oh, epochs = 20, batch_size = 35, shuffle=True)\n",
    "    loss, acc = model.evaluate(X_test, Y_test_oh)\n",
    "    Accuracy[i]=acc\n",
    "    \n",
    "print(Accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56544502  0.52849741  0.56632653  0.53170732  0.555     ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Accuracy)  \n",
    "#print(Y_train_oh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a test accuracy between 80% and 95%. Run the cell below to see the mislabelled examples. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
